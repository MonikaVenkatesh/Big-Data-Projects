
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

default_args = {
    'start_date': datetime(2024, 1, 1),
}

def extract():
    import pandas as pd
    df = pd.read_csv('/opt/airflow/data/sample_data.csv')
    df.to_pickle('/opt/airflow/data/temp.pkl')

def transform():
    import pandas as pd
    df = pd.read_pickle('/opt/airflow/data/temp.pkl')
    df_filtered = df[df['city'] == 'New York']
    df_filtered.to_pickle('/opt/airflow/data/filtered.pkl')

def load():
    import pandas as pd
    import psycopg2
    df = pd.read_pickle('/opt/airflow/data/filtered.pkl')
    conn = psycopg2.connect(
        host='postgres',
        dbname='airflow',
        user='airflow',
        password='airflow'
    )
    cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS people (
            id INT,
            name TEXT,
            age INT,
            city TEXT
        );
    """)
    for _, row in df.iterrows():
        cur.execute(
            "INSERT INTO people (id, name, age, city) VALUES (%s, %s, %s, %s);",
            (row['id'], row['name'], row['age'], row['city'])
        )
    conn.commit()
    cur.close()
    conn.close()

with DAG(
    dag_id='csv_to_postgres',
    schedule=None,
    default_args=default_args,
    catchup=False,
    tags=['etl', 'beginner']
) as dag:

    t1 = PythonOperator(task_id='extract_csv', python_callable=extract)
    t2 = PythonOperator(task_id='transform_filter', python_callable=transform)
    t3 = PythonOperator(task_id='load_postgres', python_callable=load)

    t1 >> t2 >> t3
