# Big Data Projects Portfolio

Welcome to my Big Data Projects Repository, where I demonstrate real-world Data Engineering and Big Data pipelines built using modern tools such as Apache Spark, Kafka, Airflow, Hadoop, Databricks, Snowflake, and Tableau.

Each folder inside this repository represents a tool or technology — and within it, you’ll find a complete project implemented using that specific stack.


## Repository Structure

| Folder | Description |
|---------|--------------|
| **Apache_Airflow/** | Workflow orchestration – scheduling ETL pipelines using DAGs |
| **Apache_Spark/** | Distributed batch processing with PySpark |
| **Kafka/** | Real-time streaming of transaction data |
| **Hadoop/** | Classic big data batch ETL using HDFS and MapReduce |
| **Snowflake/** | Cloud data warehouse integration and analytics |
| **Databricks_Projects/** | Unified data engineering & machine learning notebooks |
| **Tableau/** | Dashboard visualization of final transaction summaries |
| **Stock_Market_Analysis/** | Analytical project focusing on time-series and insights |



## Skills & Concepts Covered

- **Data Ingestion:** Kafka Producers & Consumers, API-based ingestion  
- **ETL Processing:** Spark, Hadoop MapReduce, and Python pipelines  
- **Data Orchestration:** Apache Airflow, Autosys  
- **Data Storage:** HDFS, Snowflake, Databricks Delta Tables  
- **Visualization:** Tableau dashboards and Excel reports  
- **Data Modeling:** Dimensional modeling, Fact/Dimension table design  
- **Automation:** Parameterized SQL, config-based ETL, reusability patterns  



